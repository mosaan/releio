# アーキテクチャ説明書（方向づけフェーズ／Mastra UC1 MVP対応版）

この文書は、Releio v2 方向づけフェーズで検証・実装済みのアーキテクチャ概要をまとめる。特に「UC1: 基本的なAI会話（Mastraベース）」の追加に加え、v2でも残る基盤（3プロセス構成・IPCストリーミング・統合ロギングなど）の現時点の状態を記録する。今後、他のコアユースケースを実装するたびに本書を改訂していく。

## 1. 目的と位置づけ

- 目的: v1のカスタムAI統合をMastraベースに置き換えつつ、既存の3プロセス構成と汎用基盤（IPC・ロギング・設定/DB）を生かしたまま、最小MVPのストリーミングチャットを成立させること。圧縮/MCPは現行実装を暫定利用し、将来Mastra提供機能への移行を前提とする。
- フェーズ: 方向づけフェーズ（PoCに近いがUIから操作可能）。永続化はインメモリ、Mastra経路は既存チャット経路と隔離。
- スコープ外: Mastra経路でのAzureプロバイダー、DB永続化、Resource/Threadメモリ共有、Mastra側MCPツール呼び出し（後続でMastra機能へ置換予定）。

## 2. 現時点で設計検証・実装済みの要点

### 2.1 3プロセス構成とIPC
- プロセス: Main（ウィンドウ・アップデート管理）、Backend（ビジネスロジック）、Renderer（React UI）。
- IPC: `@common/connection` によるMessagePortベースのinvoke/event機構。`onEvent`は`replayLast`オプション付き（デフォルト再生あり、MastraはstreamIdフィルタで混入防止）。
- ストリーミング: Backendがイベントを逐次publishし、Rendererは`AsyncGenerator`で受信・描画（従来のAI経路とMastra経路の双方で利用）。

### 2.2 ロギング（3プロセス横断）
- electron-logで単一ファイル出力: `tmp/logs/app.log`（dev）。スコープ名付き（main/backend/renderer）。
- BackendはstdoutをMainが拾いapp.logに集約。Rendererもscope付きで同ファイルへ出力。
- Mastra経路ではチャンク長・累積長・完了時のチャンク数をINFOで記録。レンダラーも受信長をINFO出力。

### 2.3 Mastra UC1 MVP（今回追加）
- 依存: `@mastra/core@0.24.6`。
- Backend:
  - `src/backend/mastra/MastraChatService.ts`: Mastraエージェント初期化、インメモリのsession/thread管理、非同期ストリーミング実行。
  - Handler公開API: `getMastraStatus` / `startMastraSession` / `streamMastraText` / `abortMastraStream`。
  - イベント: `mastraChatChunk` / `mastraChatEnd` / `mastraChatError` / `mastraChatAborted` / `mastraToolCall` / `mastraToolResult`。
- Renderer:
  - `src/renderer/src/lib/mastra-client.ts`: AsyncGeneratorでチャンク受信、AbortSignal対応。`replayLast`はデフォルト（早着イベント捕捉）で`streamId`フィルタ。
  - `src/renderer/src/components/MastraMvpChat.tsx`: Mastra専用UI（ストリーム表示・Abort・セッションID表示）。`App`/`ChatPanel`に導線追加。
- スコープ外: Mastra経路でのAzure、DB永続化、Resource/Thread共有、Mastra MCP統合。

### 2.4 既存基盤との共存
- 既存チャット（AI SDK v5直結）、圧縮サービス、MCPマネージャ、設定UI/DBは温存。Mastra経路は別API/イベントで衝突回避。
- DB: 現状Mastraセッションはインメモリのみ。将来のThread/Resource永続化に備え、`threadId/resourceId`を返却。
- 代理の汎用機構: 圧縮/トークンカウンタ、MCPツール発火は従来経路で有効（Mastra経路は未連携）。

## 3. Mastraチャットフロー（UC1）

1. Rendererで「Mastra MVP」を開き、`startMastraSession`を呼び出して`sessionId/threadId`を取得（インメモリ管理）。
2. ユーザーメッセージを送信すると、`streamMastraText(sessionId, messages)`を呼び出し、即時戻り値として`streamId`を受け取る。
3. Backendの`MastraChatService.runStreaming`が非同期でMastraエージェントを起動し、`mastraChatChunk`を逐次送信。`mastraChatEnd`で終端、`mastraChatAborted`で中断、`mastraChatError`で失敗を通知。
4. Rendererの`mastra-client`がチャンクをAsyncGeneratorで受信し、UIへ逐次描画。AbortSignalで中断も可能。
5. 完了時に累積テキストをメモリ上の履歴に保存（セッション終了で破棄）。

## 4. 主要な設計判断

- ストリーミング非同期化: `streamMastraText`が完了までブロックするとRendererがリスナー登録前にイベントが流れ、最後にまとめて表示される問題があったため、バックグラウンド実行へ変更。
- イベントリプレイ: 早着イベントを取りこぼさないようデフォルトのリプレイを許容しつつ、`streamId`でフィルタして旧ストリームの混入を防止。
- Azure除外: Mastra経路ではAzure特有のエンドポイント対応を未検証のためサポート外と明記。OpenAI/Anthropic/Googleを優先。
- 永続化方針: MVPではBackendメモリでSession/Threadを保持。将来的にはThread/ResourceをDB化し、圧縮/MCPもMastraネイティブ機能へ移行する前提で`threadId/resourceId`を返却。

## 4.1 設計モデルのビュー（役割分担と主要クラス）

- Main: ウィンドウ管理・アップデート・ログ集約（backend stdout取り込み）。`app.log`への単一出力を担保。
- Backend:
  - `server.ts`/`handler.ts`: Rendererとのinvoke/eventルーティング。Mastra APIをここで公開。
  - `mastra/MastraChatService`: Mastraエージェント初期化、インメモリSession/Thread管理、非同期ストリーミング。
  - 既存サービス: 圧縮(`compression/*`)、MCP管理(`backend/mcp`)、設定/DB(`backend/settings`,`db`)、ログ(`backend/logger`).
- Renderer:
  - `lib/mastra-client`: Backend Mastra APIラッパー。AsyncGeneratorでチャンク受信。
  - `components/MastraMvpChat`: Mastra専用UI（導線は`App`/`ChatPanel`/`ChatPageWithSessions`）。
  - 既存UI/SessionManagerは従来チャット経路で温存。
- 共通:
  - `common/connection`: IPC基盤。`onEvent(replayLast?)`で最新イベントの再送制御が可能。
  - `common/types`: API/イベント/Result型を集約。

## 4.2 配置モデルのビュー（簡略）

- Node: Electronアプリ（dev: local）。  
  - Mainプロセス: `src/main/*`  
  - Backendプロセス: `src/backend/*`（MessagePortでMain/Rendererと接続）  
  - Rendererプロセス: `src/renderer/*`  
- IPC: Main↔Backend、Backend↔Renderer が MessagePort経由で双方向。Renderer→Backend invoke、Backend→Renderer event（ストリーム）。
- ログ出力: 全プロセスから`tmp/logs/app.log`へ（mainが集約）。

## 4.3 汎用の設計メカニズム

- IPCストリーミング: `Connection.publishEvent/onEvent`で逐次イベント配送。`replayLast`オプションで早着/取りこぼしを制御し、`streamId`で混入防止。
- 統合ロギング: electron-logを用い、スコープ付きログ（main/backend/renderer）。BackendのstdoutをMainが拾い、1ファイルに集約。
- セッション管理: Mastra経路はインメモリSession/Thread保持。従来チャットはDB・SessionManagerで永続化。将来、Mastra Thread/ResourceをDB化し統合予定。
- 可観測性: ストリームチャンク長・累積長をINFOで出力し、デバッグしやすいイベントログを標準化。

## 5. ファイルとAPI

- Backend:
  - `src/backend/mastra/MastraChatService.ts`
    - `getStatus(): MastraStatus`（内部用）
    - `startSession(resourceId?): SessionRecord`
    - `streamText(sessionId, messages, publishEvent): streamId`（非同期タスク起動）
    - イベント: `mastraChatChunk`, `mastraChatEnd`, `mastraChatError`, `mastraChatAborted`, `mastraToolCall`, `mastraToolResult`
  - `src/backend/handler.ts`: 上記をRendererに公開。
- 共通/Preload:
  - `src/common/types.ts`: Mastra API型、`BackendListenerAPI`に`replayLast`オプションを追加。
  - `src/preload/server.ts`: `onEvent`にオプションを渡せるよう拡張。
- Renderer:
  - `src/renderer/src/lib/mastra-client.ts`: Mastra API呼び出しラッパー＋AsyncGenerator。
  - `src/renderer/src/components/MastraMvpChat.tsx`: Mastra専用チャットUI。
  - `src/renderer/src/App.tsx`, `ChatPanel`, `ChatPageWithSessions`: 「Mastra MVP」導線。

## 6. ログとデバッグ

- Backend: 各チャンクの`chunkIndex`/`chunkLength`/`totalLength`、完了時の`textLength`と`chunks`をINFO出力。
- Renderer: チャンク受信長、完了時の全文長をINFO出力（ログスコープは`renderer`）。
- 問題解析手順: `tmp/logs/app.log` を確認し、Backendのチャンク総数とRendererの受信ログを突き合わせる。取りこぼしがあれば`replayLast`設定や`streamId`フィルタを確認。

## 7. 既知の除外と今後

- 除外: Azureプロバイダー、DB永続化、Mastra側でのMCP呼び出し、Resource/Threadメモリ共有、圧縮・要約との統合。
- 今後: コアユースケース追加ごとに本書を改訂し、DB永続化・モデル選択UIのMastra統合・MCP連携（Mastra経路）を順次取り込む。

## 8. 受け入れ状態（本版）

- Mastra経路でのチャットがUI上でストリーミング表示されること。
- Backendログにチャンク逐次、完了ログが出ており、Renderer側でもチャンク長が記録されること。
- 既存v1チャット経路への副作用なし（独立APIとイベント名で隔離）。
